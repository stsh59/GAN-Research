{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2a35a3-8128-4007-8b7e-afdfabad5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76203699-71aa-472e-8dad-2ee626400f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(self, images, imagesSegmentation, labels):\n",
    "    ytrain = torch.eye(4)[labels]  # Convert labels to one-hot encoding\n",
    "    self.images = torch.tensor(images).float()\n",
    "    self.imagesSegmentation = torch.tensor(imagesSegmentation).float()\n",
    "    self.labels = torch.tensor(ytrain).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eea005d-0eb1-47bb-a44d-48f03ba29c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_space, labels_dim, kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(latent_space + labels_dim, 1024)\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "\n",
    "        x = torch.cat((noise, labels), dim=1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return generated_images, segmentation_images\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size, padding='same')\n",
    "\n",
    "    def forward(self, img_input, img_seg_input):\n",
    "        x = torch.cat((img_input, img_seg_input), dim=1)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return outputs, labels_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a1656-fc5b-4c50-ad2c-393ee41413e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAlgorithm(self, G, D):\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    optimizer_D = optim.RMSprop(D.parameters(), lr=self.eta, alpha=self.weight_decay)\n",
    "    optimizer_G = optim.RMSprop(G.parameters(), lr=self.eta * 0.5, alpha=self.weight_decay * 0.5)\n",
    "\n",
    "    for epoch in range(self.epochs):\n",
    "        # Get batch indices\n",
    "        indexs = np.random.randint(0, len(self.images), size=self.batch_size)\n",
    "        real_images = self.images[indexs]\n",
    "        real_img_seg = self.imagesSegmentation[indexs]\n",
    "        real_labels = self.labels[indexs]\n",
    "        real_tag = torch.ones(self.batch_size)\n",
    "\n",
    "        # Generate noise and labels\n",
    "        noise = torch.randn(self.batch_size, self.latent_space)\n",
    "        fake_labels = torch.tensor(np.eye(4)[np.random.choice(4, size=self.batch_size)])\n",
    "\n",
    "        # Generate fake images and segmentations\n",
    "        with torch.no_grad():\n",
    "            fake_images, fake_segmentations = G(noise, fake_labels)\n",
    "\n",
    "        fake_tag = torch.zeros(self.batch_size)\n",
    "\n",
    "        # Combine real and fake data\n",
    "        all_images = torch.vstack([real_images, fake_images])\n",
    "        all_segmentations = torch.vstack([real_img_seg, fake_segmentations])\n",
    "        all_labels = torch.vstack([real_labels, fake_labels])\n",
    "        all_tags = torch.hstack([real_tag, fake_tag])\n",
    "\n",
    "        # Train discriminator\n",
    "        D.train()\n",
    "        optimizer_D.zero_grad()\n",
    "        d_output, d_labels_output = D(all_images, all_segmentations)\n",
    "        d_loss_tag = criterion(d_output, all_tags)\n",
    "        d_loss_labels = criterion_ce(d_labels_output, all_labels.argmax(dim=1))\n",
    "        d_loss = d_loss_tag + d_loss_labels\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train GAN\n",
    "        GAN.train()\n",
    "        optimizer_GAN.zero_grad()\n",
    "        gan_noise = torch.randn(self.batch_size, self.latent_space)\n",
    "        gan_labels = torch.tensor(np.eye(4)[np.random.choice(4, size=self.batch_size)])\n",
    "        gan_output = GAN(gan_noise, gan_labels)\n",
    "        g_loss_tag = criterion(gan_output[0], real_tag)\n",
    "        g_loss_labels = criterion_ce(gan_output[1], gan_labels.argmax(dim=1))\n",
    "        g_loss = g_loss_tag + g_loss_labels\n",
    "        g_loss.backward()\n",
    "        optimizer_GAN.step()\n",
    "\n",
    "        # Print loss periodically\n",
    "        if epoch % 5000 == 0:\n",
    "            print(f'Epoch: {epoch}')\n",
    "            print(f'Discriminator loss: [tag: {d_loss_tag.item()}, labels: {d_loss_labels.item()}], '\n",
    "                  f'Generator loss: [tag: {g_loss_tag.item()}, labels: {g_loss_labels.item()}]')\n",
    "            self.samples(G, gan_noise, gan_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
